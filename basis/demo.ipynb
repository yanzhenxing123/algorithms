{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. 使用 tensor 初始化一个 1 × 3 的矩阵M 和一个2 × 1 的矩阵N，对两矩阵进行减法操作（要求实现三种不同的形式），给出结果并分析三种方式的不同（如果出现报错，分析报错的原因），同时需要指出在计算过程中发生了什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [-1,  0,  1]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "li_m = [[1, 2, 3]] # 1 x 3\n",
    "li_n = [[1], [2]] # 2 x 1\n",
    "M = torch.tensor(li_m)\n",
    "N = torch.tensor(li_n)\n",
    "print(M-N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [-1,  0,  1]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.sub(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 3] doesn't match the broadcast shape [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ee4d90c31583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 3] doesn't match the broadcast shape [2, 3]"
     ]
    }
   ],
   "source": [
    "print(M.sub_(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本操作实验2\n",
    "1) 利用 𝐓𝐞𝐧𝐬𝐨𝐫 创建两个大小分别 𝟑×𝟐 和 𝟒×𝟐 的随机数矩阵 𝑷 和 𝑸 ，要求服从均值为0，标准差0.01为的正态分布 \\\n",
    "2) 对第二步得到的矩阵 𝑸 进行形状变换得到 𝑸 的转置 $𝑸^𝑻$  \\\n",
    "3) 对上述得到的矩阵 𝑷 和矩阵 $𝑸^𝑻$ 求内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:tensor([[ 0.0127, -0.0046],\n",
      "        [-0.0085,  0.0122],\n",
      "        [-0.0041, -0.0023]])\n",
      "Q:tensor([[ 0.0069, -0.0133],\n",
      "        [-0.0095, -0.0051],\n",
      "        [ 0.0098,  0.0059],\n",
      "        [ 0.0149,  0.0137]])\n"
     ]
    }
   ],
   "source": [
    "P = torch.normal(0, 0.01, size=(3, 2))\n",
    "Q = torch.normal(0, 0.01, size=(4, 2))\n",
    "print('P:{}\\nQ:{}'.format(P, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0069, -0.0095,  0.0098,  0.0149],\n",
       "        [-0.0133, -0.0051,  0.0059,  0.0137]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_T = Q.T # size = 2 x 4\n",
    "Q_T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4737e-04, -9.6249e-05,  9.7251e-05,  1.2602e-04],\n",
       "        [-2.2110e-04,  1.7617e-05, -1.1467e-05,  4.0608e-05],\n",
       "        [ 2.3747e-06,  5.0479e-05, -5.3604e-05, -9.2226e-05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵运算P和Q.t\n",
    "torch.mm(P, Q_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本操作实验3\n",
    "给定公式$𝑦_3=𝑦_1+𝑦_2=𝑥^2+𝑥^3$，且 $𝑥=1$。利用学习所得到的Tensor的相关知识，求$𝑦_3$对的梯度𝑥，即$𝑑𝑦_3$/$𝑑𝑥$。要求在计算过程中，在计算 $𝑥^3$ 时中断梯度的追踪，观察结果并进行原因分析\n",
    "\n",
    "$x^3$的梯度是2而不是5的原因：\\\n",
    "由于 $y_2$的定义是被torch.no_grad():包裹的，所以与$y_2$有关的梯度是不会回传的，只有与$y_1$有关的梯度才会回传，即$x^2$对 $x$的梯度。\\\n",
    "而y2.requires_grad=False，所以不能调用 y2.backward()，会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "tensor(6.)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#创建一个二元函数，即z=f(x,y)=x2+y2，x可求导，y设置不可求导\n",
    "x=torch.tensor(3.0,requires_grad=True)\n",
    "y=torch.tensor(4.0,requires_grad=False)\n",
    "z=torch.pow(x,2)+torch.pow(y,2)\n",
    "\n",
    "#判断x,y是否是可以求导的\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "print(z.requires_grad)\n",
    "\n",
    "#求导，通过backward函数来实现\n",
    "z.backward()\n",
    "\n",
    "#查看导数，也即所谓的梯度\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor(4., requires_grad=True)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
