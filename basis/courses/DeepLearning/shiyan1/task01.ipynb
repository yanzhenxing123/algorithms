{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. ä½¿ç”¨ tensor åˆå§‹åŒ–ä¸€ä¸ª 1 Ã— 3 çš„çŸ©é˜µM å’Œä¸€ä¸ª2 Ã— 1 çš„çŸ©é˜µNï¼Œå¯¹ä¸¤çŸ©é˜µè¿›è¡Œå‡æ³•æ“ä½œï¼ˆè¦æ±‚å®ç°ä¸‰ç§ä¸åŒçš„å½¢å¼ï¼‰ï¼Œç»™å‡ºç»“æœå¹¶åˆ†æä¸‰ç§æ–¹å¼çš„ä¸åŒï¼ˆå¦‚æœå‡ºç°æŠ¥é”™ï¼Œåˆ†ææŠ¥é”™çš„åŸå› ï¼‰ï¼ŒåŒæ—¶éœ€è¦æŒ‡å‡ºåœ¨è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä»€ä¹ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [-1,  0,  1]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "li_m = [[1, 2, 3]] # 1 x 3\n",
    "li_n = [[1], [2]] # 2 x 1\n",
    "M = torch.tensor(li_m)\n",
    "N = torch.tensor(li_n)\n",
    "print(M-N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [-1,  0,  1]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.sub(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 3] doesn't match the broadcast shape [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ee4d90c31583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 3] doesn't match the broadcast shape [2, 3]"
     ]
    }
   ],
   "source": [
    "print(M.sub_(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºæœ¬æ“ä½œå®éªŒ2\n",
    "1) åˆ©ç”¨ ğ“ğğ§ğ¬ğ¨ğ« åˆ›å»ºä¸¤ä¸ªå¤§å°åˆ†åˆ« ğŸ‘Ã—ğŸ å’Œ ğŸ’Ã—ğŸ çš„éšæœºæ•°çŸ©é˜µ ğ‘· å’Œ ğ‘¸ ï¼Œè¦æ±‚æœä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®0.01ä¸ºçš„æ­£æ€åˆ†å¸ƒ \\\n",
    "2) å¯¹ç¬¬äºŒæ­¥å¾—åˆ°çš„çŸ©é˜µ ğ‘¸ è¿›è¡Œå½¢çŠ¶å˜æ¢å¾—åˆ° ğ‘¸ çš„è½¬ç½® $ğ‘¸^ğ‘»$  \\\n",
    "3) å¯¹ä¸Šè¿°å¾—åˆ°çš„çŸ©é˜µ ğ‘· å’ŒçŸ©é˜µ $ğ‘¸^ğ‘»$ æ±‚å†…ç§¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:tensor([[ 0.0127, -0.0046],\n",
      "        [-0.0085,  0.0122],\n",
      "        [-0.0041, -0.0023]])\n",
      "Q:tensor([[ 0.0069, -0.0133],\n",
      "        [-0.0095, -0.0051],\n",
      "        [ 0.0098,  0.0059],\n",
      "        [ 0.0149,  0.0137]])\n"
     ]
    }
   ],
   "source": [
    "P = torch.normal(0, 0.01, size=(3, 2))\n",
    "Q = torch.normal(0, 0.01, size=(4, 2))\n",
    "print('P:{}\\nQ:{}'.format(P, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0069, -0.0095,  0.0098,  0.0149],\n",
       "        [-0.0133, -0.0051,  0.0059,  0.0137]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_T = Q.T # size = 2 x 4\n",
    "Q_T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4737e-04, -9.6249e-05,  9.7251e-05,  1.2602e-04],\n",
       "        [-2.2110e-04,  1.7617e-05, -1.1467e-05,  4.0608e-05],\n",
       "        [ 2.3747e-06,  5.0479e-05, -5.3604e-05, -9.2226e-05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# çŸ©é˜µè¿ç®—På’ŒQ.t\n",
    "torch.mm(P, Q_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºæœ¬æ“ä½œå®éªŒ3\n",
    "ç»™å®šå…¬å¼$ğ‘¦_3=ğ‘¦_1+ğ‘¦_2=ğ‘¥^2+ğ‘¥^3$ï¼Œä¸” $ğ‘¥=1$ã€‚åˆ©ç”¨å­¦ä¹ æ‰€å¾—åˆ°çš„Tensorçš„ç›¸å…³çŸ¥è¯†ï¼Œæ±‚$ğ‘¦_3$å¯¹çš„æ¢¯åº¦ğ‘¥ï¼Œå³$ğ‘‘ğ‘¦_3$/$ğ‘‘ğ‘¥$ã€‚è¦æ±‚åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œåœ¨è®¡ç®— $ğ‘¥^3$ æ—¶ä¸­æ–­æ¢¯åº¦çš„è¿½è¸ªï¼Œè§‚å¯Ÿç»“æœå¹¶è¿›è¡ŒåŸå› åˆ†æ\n",
    "\n",
    "$x^3$çš„æ¢¯åº¦æ˜¯2è€Œä¸æ˜¯5çš„åŸå› ï¼š\\\n",
    "ç”±äº $y_2$çš„å®šä¹‰æ˜¯è¢«torch.no_grad():åŒ…è£¹çš„ï¼Œæ‰€ä»¥ä¸$y_2$æœ‰å…³çš„æ¢¯åº¦æ˜¯ä¸ä¼šå›ä¼ çš„ï¼Œåªæœ‰ä¸$y_1$æœ‰å…³çš„æ¢¯åº¦æ‰ä¼šå›ä¼ ï¼Œå³$x^2$å¯¹ $x$çš„æ¢¯åº¦ã€‚\\\n",
    "è€Œy2.requires_grad=Falseï¼Œæ‰€ä»¥ä¸èƒ½è°ƒç”¨ y2.backward()ï¼Œä¼šæŠ¥é”™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ ¹æ®é¢˜ç›®ç»™çš„å·²çŸ¥è¿›è¡Œåˆå§‹åŒ–\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "y1 = torch.pow(x, 2)\n",
    "# ä¸­æ–­x^3çš„æ¢¯åº¦è¿½è¸ª\n",
    "with torch.no_grad():\n",
    "    y2 = torch.pow(x, 3)\n",
    "y3 = y1 + y2\n",
    "x.requires_grad, y1.requires_grad, y2.requires_grad, y3.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, y1.requires_grad, y2.requires_grad, y3.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o1æ¥è®°å½•y1\n",
    "o1 = y1.sum()\n",
    "o1.backward(retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o3æ¥è®°å½•y3\n",
    "o3 = y3.sum()\n",
    "x.grad.zero_()  # å¦‚æœæ²¡æœ‰æ¸…é›¶ä¼šæœ‰å åŠ \n",
    "o3.backward(retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-56e24d6bc4ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# è°ƒç”¨ç¦ç”¨çš„å˜é‡y2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mo2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mo2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# å‡ºé”™äº†\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# è°ƒç”¨ç¦ç”¨çš„å˜é‡y2\n",
    "o2 = y2.sum()\n",
    "o2.backward()\n",
    "\n",
    "# å‡ºé”™äº†"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
